{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DcN2MtVTBi45"
   },
   "source": [
    "# Assignment 2: Sentiment Classification Using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N78gaCGOBs3n",
    "outputId": "fd707cb6-3770-4d09-fc2d-ea807237d9ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o8aAZ6nrBi47"
   },
   "source": [
    "## Programming Assignment (100 Points scaled to 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7jowkxVNBi47"
   },
   "source": [
    "For this assignment we will be implementing a naive bayes baseline classifier. Additionally, we will be using pytorch to implement a binary logistic regression classifier. Our task is sentiment classification for hotel reviews. The input to your model will be a text review, and the output label is a 1 or 0 marking it as positive or negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0tUhenSRBi48"
   },
   "source": [
    "We have provided a util.py file for loading the data, and some of the basic modeling. Your task is to fill in the functions below in order to train as accurate a classifier as possible!\n",
    "\n",
    "We suggest browsing the util.py script first. Additionally, make sure to install dependencies from the provided requirements.txt file in a similar fashion to the pytorch tutorial. With your environment activated int he terminal, run:\n",
    "```\n",
    "pip install -r requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "CoP0YxzEB6XV"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/content/drive/MyDrive/Assignment2_Sentiment_Analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eVkS1Ab54xhL",
    "outputId": "a1190c10-32ba-48b1-e335-ba8eed19b7ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en_core_web_sm (from -r requirements.txt (line 3))\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.4.0/en_core_web_sm-3.4.0.tar.gz (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m98.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (2.0.1+cu118)\n",
      "Requirement already satisfied: spacy<4.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (3.6.1)\n",
      "Collecting spacytextblob (from -r requirements.txt (line 4))\n",
      "  Downloading spacytextblob-4.0.0-py3-none-any.whl (4.5 kB)\n",
      "Collecting sklearn (from -r requirements.txt (line 5))\n",
      "  Downloading sklearn-0.0.post9.tar.gz (3.6 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (4.66.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (4.5.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (3.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (3.1.2)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (2.0.0)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->-r requirements.txt (line 1)) (3.27.5)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->-r requirements.txt (line 1)) (17.0.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->-r requirements.txt (line 2)) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->-r requirements.txt (line 2)) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->-r requirements.txt (line 2)) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->-r requirements.txt (line 2)) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->-r requirements.txt (line 2)) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->-r requirements.txt (line 2)) (8.1.12)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->-r requirements.txt (line 2)) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->-r requirements.txt (line 2)) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->-r requirements.txt (line 2)) (2.0.10)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->-r requirements.txt (line 2)) (0.9.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->-r requirements.txt (line 2)) (0.10.2)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->-r requirements.txt (line 2)) (6.4.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->-r requirements.txt (line 2)) (1.23.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->-r requirements.txt (line 2)) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->-r requirements.txt (line 2)) (1.10.13)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->-r requirements.txt (line 2)) (67.7.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->-r requirements.txt (line 2)) (23.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->-r requirements.txt (line 2)) (3.3.0)\n",
      "Collecting spacy<4.0.0,>=3.0.0 (from -r requirements.txt (line 2))\n",
      "  Downloading spacy-3.4.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting wasabi<1.1.0,>=0.9.1 (from spacy<4.0.0,>=3.0.0->-r requirements.txt (line 2))\n",
      "  Downloading wasabi-0.10.1-py3-none-any.whl (26 kB)\n",
      "Collecting typer<0.8.0,>=0.3.0 (from spacy<4.0.0,>=3.0.0->-r requirements.txt (line 2))\n",
      "  Downloading typer-0.7.0-py3-none-any.whl (38 kB)\n",
      "Collecting textblob<0.16.0,>=0.15.3 (from spacytextblob->-r requirements.txt (line 4))\n",
      "  Downloading textblob-0.15.3-py2.py3-none-any.whl (636 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m636.5/636.5 kB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->-r requirements.txt (line 2)) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->-r requirements.txt (line 2)) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->-r requirements.txt (line 2)) (2.0.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->-r requirements.txt (line 2)) (2023.7.22)\n",
      "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.10/dist-packages (from textblob<0.16.0,>=0.15.3->spacytextblob->-r requirements.txt (line 4)) (3.8.1)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<4.0.0,>=3.0.0->-r requirements.txt (line 2)) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<4.0.0,>=3.0.0->-r requirements.txt (line 2)) (0.1.3)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy<4.0.0,>=3.0.0->-r requirements.txt (line 2)) (8.1.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->-r requirements.txt (line 1)) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob<0.16.0,>=0.15.3->spacytextblob->-r requirements.txt (line 4)) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob<0.16.0,>=0.15.3->spacytextblob->-r requirements.txt (line 4)) (2023.6.3)\n",
      "Building wheels for collected packages: en_core_web_sm, sklearn\n",
      "  Building wheel for en_core_web_sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for en_core_web_sm: filename=en_core_web_sm-3.4.0-py3-none-any.whl size=12803013 sha256=8e273c2ff84252141bd4c633967dd4c18776cd5c80c61d66cddd79f7b4bdc4ed\n",
      "  Stored in directory: /root/.cache/pip/wheels/dd/7c/52/87b6e1bfdc0066764271ae0269b8bb1578147e84e984f0e0a6\n",
      "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sklearn: filename=sklearn-0.0.post9-py3-none-any.whl size=2952 sha256=e4ea83cd1389051892cd5a958039c7ab5b33648bc7932887df4b1cd595b03195\n",
      "  Stored in directory: /root/.cache/pip/wheels/33/a3/d2/092b519e9522b4c91608b7dcec0dd9051fa1bff4c45f4502d1\n",
      "Successfully built en_core_web_sm sklearn\n",
      "Installing collected packages: wasabi, sklearn, typer, textblob, spacy, spacytextblob, en_core_web_sm\n",
      "  Attempting uninstall: wasabi\n",
      "    Found existing installation: wasabi 1.1.2\n",
      "    Uninstalling wasabi-1.1.2:\n",
      "      Successfully uninstalled wasabi-1.1.2\n",
      "  Attempting uninstall: typer\n",
      "    Found existing installation: typer 0.9.0\n",
      "    Uninstalling typer-0.9.0:\n",
      "      Successfully uninstalled typer-0.9.0\n",
      "  Attempting uninstall: textblob\n",
      "    Found existing installation: textblob 0.17.1\n",
      "    Uninstalling textblob-0.17.1:\n",
      "      Successfully uninstalled textblob-0.17.1\n",
      "  Attempting uninstall: spacy\n",
      "    Found existing installation: spacy 3.6.1\n",
      "    Uninstalling spacy-3.6.1:\n",
      "      Successfully uninstalled spacy-3.6.1\n",
      "  Attempting uninstall: en_core_web_sm\n",
      "    Found existing installation: en-core-web-sm 3.6.0\n",
      "    Uninstalling en-core-web-sm-3.6.0:\n",
      "      Successfully uninstalled en-core-web-sm-3.6.0\n",
      "Successfully installed en_core_web_sm-3.4.0 sklearn-0.0.post9 spacy-3.4.4 spacytextblob-4.0.0 textblob-0.15.3 typer-0.7.0 wasabi-0.10.1\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "7De8nmtpBi48"
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import spacy\n",
    "import torch\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BpI9Dy1BBi49"
   },
   "source": [
    "## Section 1: Sentiment Classification Dataset (Total: 20 Points)\n",
    "\n",
    "The training data for this task consists of a collection of short hotel reviews. The data is formatted as one review per line. Each line starts with a unique identifier for the review (as in ID-2001) followed by tab and the text of the review.  The reviews are not tokenized or sentence segmented in any way (the words are space separated). The positive reviews and negative reviews appear in separate files namely [hotelPosT-train.txt](data/hotelPosT-train.txt) and [hotelNegT-train.txt](data/hotelNegT-train.txt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "PWCbiqPKBi4-"
   },
   "outputs": [],
   "source": [
    "from util import load_train_data\n",
    "pos_datapath = \"data/hotelPosT-train.txt\"\n",
    "neg_datapath = \"data/hotelNegT-train.txt\"\n",
    "all_texts, all_labels = load_train_data(pos_datapath, neg_datapath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-om7MjgTBi4_"
   },
   "source": [
    "### Lets look at what is in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t1vCruk4Bi5A",
    "outputId": "446ae246-abb0-4178-ebaa-89898ac3bc9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Positive Example ---\n",
      "I had a wonderful, relaxed stay at the Huntley Hotel. I wasn't staying in the priciest room, but all the staff treated me like I had reserved the penthouse. The desk clerk even helped me locate my wallet after I left it in the hotel restaurant. In addition to beautiful rooms and a kind staff, the Huntley boasts a location barely two blocks from the Santa Monica beach. When I wasn't enjoying the amenities of the hotel, I was lounging in the sun.\n",
      "\n",
      "--- Negative Example ---\n",
      "This hotel was one of the worst I have ever stayed in! When we arrived, the sheets were stained and smelled unclean. The bathroom had not been touched. There was no toilet paper or complimentary shampoos. The television did not even work. When we called the front, it took two hours for someone to come up and turn our room over. I would not recommend this hotel to anyone!\n"
     ]
    }
   ],
   "source": [
    "def random_sample(texts, labels, label):\n",
    "    data_by_label = {}\n",
    "    for lab, text in zip(labels, texts):\n",
    "        if lab not in data_by_label:\n",
    "            data_by_label[lab] = []\n",
    "        data_by_label[lab].append(text)\n",
    "    return random.choice(data_by_label[label])\n",
    "\n",
    "print(\"--- Positive Example ---\")\n",
    "print(random_sample(all_texts, all_labels, label=1))\n",
    "print(\"\\n--- Negative Example ---\")\n",
    "print(random_sample(all_texts, all_labels, label=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NbDOFZnWBi5B"
   },
   "source": [
    "### Test Data ( WAIT TILL DEADLINE)\n",
    "\n",
    "This is the test dataset that you will need to use to report the results on. This set is the unseen dataset meaning, you are not in anyway supoose to look what is in this dataset. We will release this dataset on the last day of the assignment's deadline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mbhAVHOwBi5B"
   },
   "outputs": [],
   "source": [
    "### RUN THIS ONLY ON DEADLINE ###\n",
    "# Load the test data\n",
    "\n",
    "from util import load_test_data\n",
    "\n",
    "# FIXME\n",
    "test_datapath = \"data/test-dataset.txt\"\n",
    "test_texts, test_labels = load_train_data(test_datapath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6E0HroyeBi5C"
   },
   "source": [
    "### Task 1.1: Print the number of \"positive\" and \"negative\" samples (5 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VgTeJY6YBi5C"
   },
   "source": [
    "It is important to know the distribution of the training examples. More often than not, you will have to work with datasets that are not \"balanced\" with respect to the labels of the samples. For this task, print out the number of examples that have label = 1 and label = 0, respectively, in std:out or plot a pie chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q-6l37vmBi5C",
    "outputId": "2a75c158-8821-48f3-c177-789f0234471d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of positive labels is 95 and the number of negative labels is 94\n"
     ]
    }
   ],
   "source": [
    "### ENTER CODE HERE ###\n",
    "\n",
    "# Note since we have them in two seperate files,\n",
    "# this can also be done with bash commands\n",
    "def label_distribution(labels):\n",
    "    posnum = 0\n",
    "    negnum = 0\n",
    "    for i in labels:\n",
    "      if i == 1:\n",
    "        posnum = posnum + 1\n",
    "      elif i == 0:\n",
    "        negnum = negnum + 1\n",
    "    print(\"The number of positive labels is \" + str(posnum) + \" and the number\"\n",
    "      + \" of negative labels is \" + str(negnum))\n",
    "label_distribution(all_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5yyyN1FlBi5D"
   },
   "source": [
    "### Task 1.2: Split Training and Development Sets (5 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i6CuVMVoBi5D"
   },
   "source": [
    "For the purpose of coming with the best parameters for the model you will have to split the dataset into training and development sets. Make sure the splits follow the same distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fk5mJ98_Bi5D",
    "outputId": "c59c98ce-e259-4a33-eddc-bc211e1c272f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Label Distribution:\n",
      "The number of positive labels is 76 and the number of negative labels is 75\n",
      "Dev Label Distribution:\n",
      "The number of positive labels is 18 and the number of negative labels is 18\n"
     ]
    }
   ],
   "source": [
    "### ENTER CODE HERE ###\n",
    "\n",
    "import random\n",
    "import math\n",
    "\n",
    "\n",
    "def split_dataset(texts, labels):\n",
    "  pos_texts = texts[0:94]\n",
    "  neg_texts = texts[95:188]\n",
    "  train_texts = []\n",
    "  train_labels = []\n",
    "  dev_texts = []\n",
    "  dev_labels = []\n",
    "\n",
    "  random.shuffle(pos_texts)\n",
    "  random.shuffle(neg_texts)\n",
    "  poslen = math.ceil(0.8 * len(pos_texts))\n",
    "  neglen = math.ceil(0.8 * len(neg_texts))\n",
    "  for i in range(poslen):\n",
    "    train_texts.append(pos_texts[i])\n",
    "    train_labels.append(1)\n",
    "    if i < (len(pos_texts) - poslen):\n",
    "      dev_texts.append(pos_texts[i + poslen])\n",
    "      dev_labels.append(1)\n",
    "  for j in range(neglen):\n",
    "    train_texts.append(neg_texts[j])\n",
    "    train_labels.append(0)\n",
    "    if j < (len(neg_texts) - neglen):\n",
    "      dev_texts.append(neg_texts[j + neglen])\n",
    "      dev_labels.append(0)\n",
    "\n",
    "  return train_texts, train_labels, dev_texts, dev_labels\n",
    "\n",
    "\n",
    "train_texts, train_labels, dev_texts, dev_labels = split_dataset(all_texts, all_labels)\n",
    "\n",
    "print('Train Label Distribution:')\n",
    "label_distribution(train_labels)\n",
    "\n",
    "print('Dev Label Distribution:')\n",
    "label_distribution(dev_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wiu7udU_Bi5D"
   },
   "source": [
    "### Task 1.3: Evaluation Metrics (10 Points)\n",
    "\n",
    "Implement the evaulation metrics: Accuracy, Precision, Recall and F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "BmQgdSJjBi5D"
   },
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###\n",
    "\n",
    "def accuracy(predicted_labels, true_labels):\n",
    "    correct = 0\n",
    "    i = 0\n",
    "    for i in range(len(predicted_labels)):\n",
    "      if predicted_labels[i] == true_labels[i]:\n",
    "        correct = correct + 1\n",
    "    acc = correct / len(predicted_labels)\n",
    "    return acc\n",
    "\n",
    "def precision(predicted_labels, true_labels):\n",
    "    pallpos = 0\n",
    "    truepos = 0\n",
    "    for i in range(len(predicted_labels)-1):\n",
    "      if predicted_labels[i] == 1:\n",
    "        pallpos = pallpos + 1\n",
    "      if predicted_labels[i] == 1 and predicted_labels[i] == true_labels[i]:\n",
    "        truepos = truepos + 1\n",
    "    prec = truepos / pallpos\n",
    "    return prec\n",
    "\n",
    "def recall(predicted_labels, true_labels):\n",
    "    rallpos = 0\n",
    "    truepos = 0\n",
    "    for i in range(len(predicted_labels)):\n",
    "      if true_labels[i] == 1:\n",
    "        rallpos = rallpos + 1\n",
    "      if predicted_labels[i] == 1 and predicted_labels[i] == true_labels[i]:\n",
    "        truepos = truepos + 1\n",
    "    rec = truepos / rallpos\n",
    "    return rec\n",
    "\n",
    "\n",
    "def f1_score(predicted_labels, true_labels):\n",
    "    pallpos = 0\n",
    "    truepos = 0\n",
    "    rallpos = 0\n",
    "\n",
    "    for i in range(len(predicted_labels)-1):\n",
    "      if predicted_labels[i] == 1:\n",
    "        pallpos = pallpos + 1\n",
    "      if predicted_labels[i] == 1 and predicted_labels[i] == true_labels[i]:\n",
    "        truepos = truepos + 1\n",
    "    for i in range(len(predicted_labels)):\n",
    "      if true_labels[i] == 1:\n",
    "        rallpos = rallpos + 1\n",
    "    prec = truepos / pallpos\n",
    "    rec = truepos / rallpos\n",
    "    hmean = (2 * prec * rec) / (prec + rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "id": "UpcN5DSpBi5E",
    "outputId": "2b7d23b0-567d-450f-fbd1-0850d915bccf"
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-b7b7eaf7b5cc>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mem_test_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mem_test_labels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mem_test_precision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mem_test_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mem_test_labels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mem_test_recall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mem_test_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mem_test_labels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mem_test_f1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'All Test Cases Passed!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### DO NOT EDIT ###\n",
    "\n",
    "em_test_labels = [0]*6 + [1]*4\n",
    "em_test_predictions = [0]*8 + [1]*2\n",
    "\n",
    "em_test_accuracy = 0.8\n",
    "em_test_precision = 1.0\n",
    "em_test_recall = 0.5\n",
    "em_test_f1 = 2/3\n",
    "\n",
    "assert accuracy(em_test_predictions, em_test_labels) == em_test_accuracy\n",
    "assert precision(em_test_predictions, em_test_labels) == em_test_precision\n",
    "assert recall(em_test_predictions, em_test_labels) == em_test_recall\n",
    "assert f1_score(em_test_predictions, em_test_labels) == em_test_f1\n",
    "\n",
    "print('All Test Cases Passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JqRtY3nQBi5E"
   },
   "source": [
    "## Section 2: Baselines (Total: 20 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yni3OobdBi5E"
   },
   "source": [
    "It is important to come up with baselines for the classifications to compare the more complicated models with. The baselines are also useful as a debugging method for your actual classfication model. You will create two baselines:\n",
    "\n",
    "1. Random Chance\n",
    "2. Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yx7_O5u-Bi5E"
   },
   "source": [
    "### Task 2.1: Random Chance Classifier (5 Points)\n",
    "\n",
    "A random chance classifier predicts the label according to the label's distribution. As an example, if the label 1 appears 70% of the times in the training set, you predict 70 out of 100 times the label 1 and label 0 30% of the times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "xddq7AUEBi5E"
   },
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###\n",
    "\n",
    "def predict_random(train_labels, num_samples):\n",
    "    pos = 0\n",
    "    for i in train_labels:\n",
    "      if i == 1:\n",
    "        pos = pos + 1\n",
    "    distr = pos / len(train_labels)\n",
    "    distrsize = math.ceil(distr * num_samples)\n",
    "\n",
    "    pred = [1]*(distrsize) + [0]*(num_samples - distrsize)\n",
    "\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z2OCSGDkBi5E"
   },
   "source": [
    "### Task 2.2: Naive Bayes Classifier (Total: 10 Points)\n",
    "\n",
    "In the class, Jim went over how to implement a Naive Bayes Classifier using the tokens in the training samples.\n",
    "In this task, you will do the same. As a preprocessing step, you might want to remove the stop words and lemmatize/stem the words of the texts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6iBUGcpjBi5F"
   },
   "source": [
    "### Spacy Model https://spacy.io\n",
    "\n",
    "To tokenize the text and help extract features from text, we will use the popular spaCy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "9dMhVI6lBi5F"
   },
   "outputs": [],
   "source": [
    "### DO NOT EDIT ###\n",
    "\n",
    "# Initialize the spacy model\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tl3YJ3yWBi5F"
   },
   "source": [
    "### Task 2.2.1: Play around with spacy (0 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RXNsyAMyBi5F",
    "outputId": "e090352a-3b97-4614-852c-6c203aab9df5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token Lemma Is_Stopword?\n",
      "This this True\n",
      "is be True\n",
      "an an True\n",
      "amazing amazing False\n",
      "sentence sentence False\n"
     ]
    }
   ],
   "source": [
    "### ENTER CODE HERE ###\n",
    "\n",
    "test_string = \"This is an amazing sentence\"\n",
    "\n",
    "# parse the string with spacy model\n",
    "test_doc = nlp(test_string)\n",
    "\n",
    "print('Token', 'Lemma', 'Is_Stopword?')\n",
    "for token in test_doc:\n",
    "    print(token, token.lemma_, token.is_stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uo9785IRBi5G"
   },
   "source": [
    "### Task 2.2.2: Preprocessing (5 Points)\n",
    "\n",
    "Remove stopwords and lemmatize the words of a text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VXSsyY2sBi5G",
    "outputId": "edcfd910-0ca6-4fbd-ccdd-dc5d98ee6fc6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Test Cases Passed!\n"
     ]
    }
   ],
   "source": [
    "### ENTER CODE HERE ###\n",
    "\n",
    "def pre_process(text: str) -> List[str]:\n",
    "  lemmas = []\n",
    "  nlp_text = nlp(text)\n",
    "  for token in nlp_text:\n",
    "    if not token.is_stop:\n",
    "      lemmas.append(token.lemma_)\n",
    "  return lemmas\n",
    "\n",
    "test_string = \"This sentence needs to be lemmatized\"\n",
    "\n",
    "assert len({'sentence', 'need', 'lemmatize', 'lemmatiz'}.intersection(pre_process(test_string))) >= 3\n",
    "\n",
    "print('All Test Cases Passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HArs-4DgBi5H"
   },
   "source": [
    "### Task 2.2.3: The Naive Bayes Class (5 Points)\n",
    "\n",
    "The standard way of implementing classifiers like Naive Bayes is to implement the two methods: \"fit\" and \"predict\". The fit method expects the training data along with labels, and the predict method predicts the labels for the provides texts of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "e3l-U5F2Bi5H"
   },
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###\n",
    "\n",
    "class NaiveBayesClassifier:\n",
    "    def __init__(self, num_classes):\n",
    "        self.num_classes = num_classes\n",
    "        self.cls = []\n",
    "        self.prior_cls = {}\n",
    "        self.prob_cls = {}\n",
    "\n",
    "    def fit(self, texts, labels):\n",
    "      #pre-process texts\n",
    "        pr_texts = []\n",
    "        for i in range(len(texts)):\n",
    "          pr_texts.append(pre_process(texts[i]))\n",
    "      #give names to the classes of labels\n",
    "        dcls = {} #number of documents per class/label\n",
    "        for l in labels:\n",
    "          if l not in self.cls:\n",
    "            self.cls.append(l)\n",
    "      #calculate number of documents per class and sort texts\n",
    "        texts_per_class = {}\n",
    "        for cl in self.cls:\n",
    "          doc_in_class_count = 0\n",
    "          for j in range(len(labels)):\n",
    "            if labels[j] == cl:\n",
    "              doc_in_class_count = doc_in_class_count + 1\n",
    "          dcls[cl] = doc_in_class_count\n",
    "          texts_per_class[cl] = []\n",
    "       #sort texts into classes\n",
    "        for t in range(len(texts)):\n",
    "          texts_per_class[labels[t]].append(pr_texts[t])\n",
    "      #calculate vocab, priors and  for all classes\n",
    "        for cl in self.cls:\n",
    "          self.prior_cls[cl] = dcls[cl] / len(texts)\n",
    "        for c in texts_per_class:\n",
    "          class_vocab = {}\n",
    "          vocab_probability = {}\n",
    "          for tpc in texts_per_class[c]:\n",
    "            for w in tpc:\n",
    "              if w not in class_vocab:\n",
    "                class_vocab.update({w : 1})\n",
    "              else:\n",
    "                class_vocab[w] = class_vocab[w] + 1\n",
    "          for v in class_vocab:\n",
    "            vocab_probability[v] = class_vocab[v] / len(class_vocab)\n",
    "          self.prob_cls[c] = vocab_probability\n",
    "\n",
    "    def predict(self, texts):\n",
    "        predicted_classes = []\n",
    "      #pre-process texts\n",
    "        pr_texts = []\n",
    "        for i in range(len(texts)):\n",
    "          pr_texts.append(pre_process(texts[i]))\n",
    "        for j in range(len(pr_texts)):\n",
    "          possibilities = []\n",
    "          for c in self.cls:\n",
    "            c_pr = self.prior_cls[c]\n",
    "            for w in pr_texts[j]:\n",
    "              if w in self.prob_cls[c]:\n",
    "                c_pr = c_pr + self.prob_cls[c[w]]\n",
    "              possibilities.append(c_pr)\n",
    "            sorted_possibilities = possibilities.sort()\n",
    "            for p in range(len(possibilities)):\n",
    "              if possibilities[p] == sorted_possibilities[0]:\n",
    "                predicted_classes.append(c)\n",
    "        return predicted_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MIUal1V_Bi5H"
   },
   "source": [
    "### Task 2.3: Baseline Results  (5 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DWbKHLw3Bi5I"
   },
   "source": [
    "Since there is not hyperparameter-tuing required for the baselines, we can use the entirety of the training set (no need to split the dataset into train and development). Report the results you achieve with the two baselines by running the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "id": "H_TT9NMRBi5I",
    "outputId": "652b6685-f941-4380-dbb0-762258015e92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Chance F1: None\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-7b16333f846e>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mnaive_bayes_classifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNaiveBayesClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mnaive_bayes_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtestset_predictions_nb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnaive_bayes_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_texts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Naive Bayes F1:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestset_predictions_nb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-39-a000f0abfcc7>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpr_texts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprob_cls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m                 \u001b[0mc_pr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_pr\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprob_cls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m               \u001b[0mpossibilities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_pr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0msorted_possibilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpossibilities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "### DO NOT EDIT ###\n",
    "\n",
    "### DEV SET RESULTS\n",
    "\n",
    "testset_prediction_random = predict_random(train_labels, num_samples=len(dev_labels))\n",
    "print('Random Chance F1:', f1_score(testset_prediction_random, dev_labels))\n",
    "\n",
    "naive_bayes_classifier = NaiveBayesClassifier(num_classes=2)\n",
    "naive_bayes_classifier.fit(train_texts, train_labels)\n",
    "testset_predictions_nb = naive_bayes_classifier.predict(dev_texts)\n",
    "print('Naive Bayes F1:', f1_score(testset_predictions_nb, dev_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iFIn7Wz-Bi5I"
   },
   "outputs": [],
   "source": [
    "### DO NOT EDIT ###\n",
    "### RUN THIS ONLY ON DEADLINE ###\n",
    "### TEST SET RESULTS\n",
    "\n",
    "testset_prediction_random = predict_random(all_labels, num_samples=len(test_labels))\n",
    "print('Random Chance F1:', f1_score(testset_prediction_random, test_labels))\n",
    "\n",
    "naive_bayes_classifier = NaiveBayesClassifier(num_classes=2)\n",
    "naive_bayes_classifier.fit(all_texts, all_labels)\n",
    "testset_predictions_nb = naive_bayes_classifier.predict(test_texts)\n",
    "print('Naive Bayes F1:', f1_score(testset_predictions_nb, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dbb3sf8JBi5I"
   },
   "source": [
    "## Section 3: Logistic Regression on Features (Total: 60 Points)\n",
    "\n",
    "Now let's try building a logistic regression based classifier on hand-engineered features.\n",
    "\n",
    "The following tasks are going to be the implementation of the components required in building a Logistic Regressor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zXxCwtDLBi5I"
   },
   "source": [
    "### Task 3.0: Feature Extraction (20 points)\n",
    "\n",
    "This is perhaps the most challenging part of this assignment. In the class, we went over how to featurize text for a classification system for sentiment analysis. In this assignment, you should implement and build upon this to accuractely classify the hotel reviews.\n",
    "\n",
    "This task requires a thorough understanding of the dataset to answer the important question, \"What is in the data?\". Please go through some of the datapoints and convert the signals that you think might help in identifying \"sentiment\" as features.\n",
    "\n",
    "Please refer to the section in Jim's book that illustrates the process of feature engineering for this task. We have attached an image of the table below:\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "Please use the files with postive and negative words attached in the assignment: [positive_words.txt](data/poisitive-words.txt) and  [negative_words.txt](data/negative-words.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2RHaYOLQBi5J"
   },
   "outputs": [],
   "source": [
    "def make_test_feature(text: spacy.tokens.doc.Doc):\n",
    "    return \"happy\" in [t.lemma_ for t in text]\n",
    "\n",
    "\n",
    "def extract_features(text: spacy.tokens.doc.Doc):\n",
    "    features = []\n",
    "    # TODO: Replace this with your own feature extraction functions.\n",
    "    features.append(make_test_feature(text))\n",
    "    # TODO: add more features to the feature vector\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SW7X_QyZBi5J"
   },
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###\n",
    "### DO NOT CHANGE THE SIGNATURE OF THE function THOUGH ###\n",
    "\n",
    "def featurize_data(texts, labels):\n",
    "    features = [\n",
    "        extract_features(doc) for doc in nlp.pipe(texts)\n",
    "    ]\n",
    "    return torch.FloatTensor(features), torch.FloatTensor(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l5M_XE4yBi5J"
   },
   "source": [
    "### Task 3.0.2: Feature Scaling (10 Points)\n",
    "\n",
    "In this task we will use the data normalization technique to ensure the scales of the feature are consistent.\n",
    "After featurizing the dataset, we need to call the following function before passing it to the classifier\n",
    "\n",
    "#### Normalization Formula\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xNNS3t19Bi5J"
   },
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###\n",
    "\n",
    "def normalize(features: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    return the features transformed by the above formula of normalization\n",
    "    \"\"\"\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aW5f-MLHBi5J"
   },
   "source": [
    "## Training a Logistic Regression Classifier (Total: 30 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IDgoCwIJBi5K"
   },
   "source": [
    "In this section, you will implement the components needed to train the binary classifier using logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-r74alx5Bi5K"
   },
   "source": [
    "### Here we define our pytorch logistic regression classifier (DO NOT EDIT THIS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s8QF7iHnBi5K"
   },
   "outputs": [],
   "source": [
    "class SentimentClassifier(torch.nn.Module):\n",
    "    def __init__(self, input_dim: int):\n",
    "        super().__init__()\n",
    "        # We force output to be one, since we are doing binary logistic regression\n",
    "        self.output_size = 1\n",
    "        self.coefficients = torch.nn.Linear(input_dim, self.output_size)\n",
    "        # Initialize weights. Note that this is not strictly necessary,\n",
    "        # but you should test different initializations per lecture\n",
    "        initialize_weights(self.coefficients)\n",
    "\n",
    "    def forward(self, features: torch.Tensor):\n",
    "        # We predict a number by multipling by the coefficients\n",
    "        # and then take the sigmoid to turn the score as logits\n",
    "        return torch.sigmoid(self.coefficients(features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JdDySERFBi5K"
   },
   "source": [
    "### Task 3.1: Initialize the weights. (5 Points)\n",
    "\n",
    "Initialization of the parameters is an important step to ensure the SGD algorithm converges to a global optimum. Typically, we need to try different initialization methods and compare the accuracy we achieve for the development set. In this task, implement the function that initializes the parameters to ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0SsqsLI9Bi5K"
   },
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###\n",
    "\n",
    "def initialize_weights(coefficients):\n",
    "    \"\"\"\n",
    "    TODO: Replace the line `raise NotImplementedError` with your code.\n",
    "    Initialize the weights of the coefficients by assigning the parameter\n",
    "    coefficients.weights.data = ...\n",
    "    \"\"\"\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_HkjCk23Bi5L"
   },
   "source": [
    "Let's build a training function similar to the linear regressor from the tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ngJbzSenBi5L"
   },
   "source": [
    "### Task 3.2: Logistic Loss Function (10 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZyIDT-XfBi5L"
   },
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###\n",
    "\n",
    "def logistic_loss(prediction: torch.Tensor, label: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    TODO: Implement the logistic loss function between a prediction and label.\n",
    "    \"\"\"\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ddnbzd53Bi5M"
   },
   "source": [
    "### Task 3.3: Create an SGD optimizer (0 Points)\n",
    "\n",
    "We have already provided the implementation of how to create the SGD optimizer\n",
    "\n",
    "You may try different optimizers refering to the docs provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gsZEZ0dhBi5M"
   },
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###\n",
    "\n",
    "def make_optimizer(model, learning_rate) -> torch.optim:\n",
    "    \"\"\"\n",
    "    Returns an Stocastic Gradient Descent Optimizer\n",
    "    See here for algorithms you can import: https://pytorch.org/docs/stable/optim.html\n",
    "    \"\"\"\n",
    "    return torch.optim.SGD(model.parameters(), learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KAkJe2heBi5M"
   },
   "source": [
    "### Task 3.5: Converting Logits into Predictions (5 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3WRp9VGMBi5M"
   },
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###\n",
    "\n",
    "def predict(model, features):\n",
    "    with torch.no_grad():\n",
    "        \"\"\"\n",
    "        TODO: Replace the line `raise NotImplementedError`\n",
    "        with the logic of converting the logits into prediction labels (0, 1)\n",
    "        \"\"\"\n",
    "        logits = model(features)\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xr9ER65QBi5M"
   },
   "source": [
    "### Training Function (DO NOT EDIT THIS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wrVOaV4ABi5N"
   },
   "outputs": [],
   "source": [
    "### DO NOT EDIT ###\n",
    "\n",
    "from tqdm.autonotebook import tqdm\n",
    "import random\n",
    "\n",
    "\n",
    "def training_loop(\n",
    "    num_epochs,\n",
    "    batch_size,\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    dev_features,\n",
    "    dev_labels,\n",
    "    optimizer,\n",
    "    model\n",
    "):\n",
    "    samples = list(zip(train_features, train_labels))\n",
    "    random.shuffle(samples)\n",
    "    batches = []\n",
    "    for i in range(0, len(samples), batch_size):\n",
    "        batches.append(samples[i:i+batch_size])\n",
    "    print(\"Training...\")\n",
    "    for i in range(num_epochs):\n",
    "        losses = []\n",
    "        for batch in tqdm(batches):\n",
    "            # Empty the dynamic computation graph\n",
    "            features, labels = zip(*batch)\n",
    "            features = torch.stack(features)\n",
    "            labels = torch.stack(labels)\n",
    "            optimizer.zero_grad()\n",
    "            # Run the model\n",
    "            logits = model(features)\n",
    "            # Compute loss\n",
    "            loss = logistic_loss(torch.squeeze(logits), labels)\n",
    "            # In this logistic regression example,\n",
    "            # this entails computing a single gradient\n",
    "            loss.backward()\n",
    "            # Backpropogate the loss through our model\n",
    "\n",
    "            # Update our coefficients in the direction of the gradient.\n",
    "            optimizer.step()\n",
    "             # For logging\n",
    "            losses.append(loss.item())\n",
    "\n",
    "        # Estimate the f1 score for the development set\n",
    "        dev_f1 = f1_score(predict(model, dev_features), dev_labels)\n",
    "        print(f\"epoch {i}, loss: {sum(losses)/len(losses)}\")\n",
    "        print(f\"Dev F1 {dev_f1}\")\n",
    "\n",
    "    # Return the trained model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZK2RVG06Bi5N"
   },
   "source": [
    "### Task 3.6: Train the classifier (10 Points)\n",
    "\n",
    "Run the following cell to train a logistic regressor on your hand-engineered features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A2rlrIKCBi5N"
   },
   "outputs": [],
   "source": [
    "### DO NOT EDIT ###\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "train_features, train_labels_tensor = featurize_data(train_texts, train_labels)\n",
    "train_features = normalize(train_features)\n",
    "dev_features, dev_labels_tensor = featurize_data(dev_texts, dev_labels)\n",
    "dev_features = normalize(dev_features)\n",
    "model = SentimentClassifier(train_features.shape[1])\n",
    "optimizer = make_optimizer(model, learning_rate=0.01)\n",
    "\n",
    "trained_model = training_loop(\n",
    "    num_epochs,\n",
    "    16,\n",
    "    train_features,\n",
    "    train_labels_tensor,\n",
    "    dev_features,\n",
    "    dev_labels_tensor,\n",
    "    optimizer,\n",
    "    model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jLBJXauuBi5N"
   },
   "source": [
    "### Task 3.7: Get the predictions on the Test Set using the Trained model and print the F1 score (10 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0PyO5h30Bi5N"
   },
   "outputs": [],
   "source": [
    "### DO NOT EDIT ###\n",
    "\n",
    "### DEV SET RESULTS\n",
    "\n",
    "test_features, test_labels = featurize_data(dev_texts, dev_labels)\n",
    "print('Logistic Regression Results:')\n",
    "print('Accuracy:', accuracy(predict(trained_model, test_features), test_labels))\n",
    "print('F1-score', f1_score(predict(trained_model, test_features), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vr4JELxzBi5O"
   },
   "outputs": [],
   "source": [
    "### DO NOT EDIT ###\n",
    "### RUN THIS ONLY ON DEADLINE ###\n",
    "### TEST SET RESULTS\n",
    "\n",
    "test_features, test_labels = featurize_data(test_texts, test_labels)\n",
    "print('Logistic Regression Results:')\n",
    "print('Accuracy:', accuracy(predict(trained_model, test_features), test_labels))\n",
    "print('F1-score', f1_score(predict(trained_model, test_features), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "shHzqHozBi5O"
   },
   "source": [
    "## Written Assignment (60 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bpkj8j4TBi5O"
   },
   "source": [
    "Written assignment tests the understanding of the student for the assignment's task. We have split the writing into sections. You will need to write 1-2 paragraphs describing the sections. Please be concise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fVbLFoy2Bi5O"
   },
   "source": [
    "### In your own words, describe what the task is (20 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gNAzDcDHBi5O"
   },
   "source": [
    "Describe the task, how is it useful and an example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MLeZIklpBi5P"
   },
   "source": [
    "### Describe your method for the task (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oor6Wll8Bi5P"
   },
   "source": [
    "Important details about the implementation. Feature engineering, parameter choice etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LWCodK1iBi5P"
   },
   "source": [
    "### Experiment Results (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YU7kUc8RBi5P"
   },
   "source": [
    "Typically a table summarizing all the different experiment results for various parameter choices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uNRS2pxFBi5Q"
   },
   "source": [
    "### Discussion (20 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GEca7_DtBi5Q"
   },
   "source": [
    "Key takeaway from the assignment. Why is the method good? shortcomings? how would you improve? Additional thoughts?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
