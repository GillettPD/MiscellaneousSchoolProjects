{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcN2MtVTBi45"
      },
      "source": [
        "# Assignment 2: Sentiment Classification Using Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N78gaCGOBs3n",
        "outputId": "1c0eac42-43d5-4b87-92b3-fd61f3439db3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8aAZ6nrBi47"
      },
      "source": [
        "## Programming Assignment (100 Points scaled to 40)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jowkxVNBi47"
      },
      "source": [
        "For this assignment we will be implementing a naive bayes baseline classifier. Additionally, we will be using pytorch to implement a binary logistic regression classifier. Our task is sentiment classification for hotel reviews. The input to your model will be a text review, and the output label is a 1 or 0 marking it as positive or negative."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tUhenSRBi48"
      },
      "source": [
        "We have provided a util.py file for loading the data, and some of the basic modeling. Your task is to fill in the functions below in order to train as accurate a classifier as possible!\n",
        "\n",
        "We suggest browsing the util.py script first. Additionally, make sure to install dependencies from the provided requirements.txt file in a similar fashion to the pytorch tutorial. With your environment activated int he terminal, run:\n",
        "```\n",
        "pip install -r requirements.txt\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/MyDrive/Assignment2_Sentiment_Analysis\")\n",
        "\n",
        "import math\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "CoP0YxzEB6XV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVkS1Ab54xhL",
        "outputId": "a1549ace-6f38-4bb9-c629-8d9d835ce33c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en_core_web_sm (from -r requirements.txt (line 3))\n",
            "  Using cached https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.4.0/en_core_web_sm-3.4.0.tar.gz (12.8 MB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (2.0.1+cu118)\n",
            "Requirement already satisfied: spacy<4.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (3.6.1)\n",
            "Collecting spacytextblob (from -r requirements.txt (line 4))\n",
            "  Using cached spacytextblob-4.0.0-py3-none-any.whl (4.5 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (1.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (4.66.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->-r requirements.txt (line 1)) (3.27.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->-r requirements.txt (line 1)) (17.0.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->-r requirements.txt (line 2)) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->-r requirements.txt (line 2)) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->-r requirements.txt (line 2)) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->-r requirements.txt (line 2)) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->-r requirements.txt (line 2)) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->-r requirements.txt (line 2)) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->-r requirements.txt (line 2)) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->-r requirements.txt (line 2)) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->-r requirements.txt (line 2)) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->-r requirements.txt (line 2)) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->-r requirements.txt (line 2)) (0.10.2)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->-r requirements.txt (line 2)) (6.4.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->-r requirements.txt (line 2)) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->-r requirements.txt (line 2)) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->-r requirements.txt (line 2)) (1.10.13)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->-r requirements.txt (line 2)) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->-r requirements.txt (line 2)) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.0.0->-r requirements.txt (line 2)) (3.3.0)\n",
            "Collecting spacy<4.0.0,>=3.0.0 (from -r requirements.txt (line 2))\n",
            "  Downloading spacy-3.4.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wasabi<1.1.0,>=0.9.1 (from spacy<4.0.0,>=3.0.0->-r requirements.txt (line 2))\n",
            "  Downloading wasabi-0.10.1-py3-none-any.whl (26 kB)\n",
            "Collecting typer<0.8.0,>=0.3.0 (from spacy<4.0.0,>=3.0.0->-r requirements.txt (line 2))\n",
            "  Downloading typer-0.7.0-py3-none-any.whl (38 kB)\n",
            "Collecting textblob<0.16.0,>=0.15.3 (from spacytextblob->-r requirements.txt (line 4))\n",
            "  Downloading textblob-0.15.3-py2.py3-none-any.whl (636 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m636.5/636.5 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r requirements.txt (line 5)) (1.11.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r requirements.txt (line 5)) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r requirements.txt (line 5)) (3.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->-r requirements.txt (line 2)) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->-r requirements.txt (line 2)) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->-r requirements.txt (line 2)) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->-r requirements.txt (line 2)) (2023.7.22)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.10/dist-packages (from textblob<0.16.0,>=0.15.3->spacytextblob->-r requirements.txt (line 4)) (3.8.1)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<4.0.0,>=3.0.0->-r requirements.txt (line 2)) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<4.0.0,>=3.0.0->-r requirements.txt (line 2)) (0.1.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy<4.0.0,>=3.0.0->-r requirements.txt (line 2)) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->-r requirements.txt (line 1)) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob<0.16.0,>=0.15.3->spacytextblob->-r requirements.txt (line 4)) (2023.6.3)\n",
            "Building wheels for collected packages: en_core_web_sm\n",
            "  Building wheel for en_core_web_sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en_core_web_sm: filename=en_core_web_sm-3.4.0-py3-none-any.whl size=12803013 sha256=4c3df2d0a51f2a535146b61e09a4e5dc3434e29272a6328d9d1c4a90546ea878\n",
            "  Stored in directory: /root/.cache/pip/wheels/dd/7c/52/87b6e1bfdc0066764271ae0269b8bb1578147e84e984f0e0a6\n",
            "Successfully built en_core_web_sm\n",
            "Installing collected packages: wasabi, typer, textblob, spacy, spacytextblob, en_core_web_sm\n",
            "  Attempting uninstall: wasabi\n",
            "    Found existing installation: wasabi 1.1.2\n",
            "    Uninstalling wasabi-1.1.2:\n",
            "      Successfully uninstalled wasabi-1.1.2\n",
            "  Attempting uninstall: typer\n",
            "    Found existing installation: typer 0.9.0\n",
            "    Uninstalling typer-0.9.0:\n",
            "      Successfully uninstalled typer-0.9.0\n",
            "  Attempting uninstall: textblob\n",
            "    Found existing installation: textblob 0.17.1\n",
            "    Uninstalling textblob-0.17.1:\n",
            "      Successfully uninstalled textblob-0.17.1\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.6.1\n",
            "    Uninstalling spacy-3.6.1:\n",
            "      Successfully uninstalled spacy-3.6.1\n",
            "  Attempting uninstall: en_core_web_sm\n",
            "    Found existing installation: en-core-web-sm 3.6.0\n",
            "    Uninstalling en-core-web-sm-3.6.0:\n",
            "      Successfully uninstalled en-core-web-sm-3.6.0\n",
            "Successfully installed en_core_web_sm-3.4.0 spacy-3.4.4 spacytextblob-4.0.0 textblob-0.15.3 typer-0.7.0 wasabi-0.10.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7De8nmtpBi48"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "import spacy\n",
        "import torch\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpI9Dy1BBi49"
      },
      "source": [
        "## Section 1: Sentiment Classification Dataset (Total: 20 Points)\n",
        "\n",
        "The training data for this task consists of a collection of short hotel reviews. The data is formatted as one review per line. Each line starts with a unique identifier for the review (as in ID-2001) followed by tab and the text of the review.  The reviews are not tokenized or sentence segmented in any way (the words are space separated). The positive reviews and negative reviews appear in separate files namely [hotelPosT-train.txt](data/hotelPosT-train.txt) and [hotelNegT-train.txt](data/hotelNegT-train.txt)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "PWCbiqPKBi4-"
      },
      "outputs": [],
      "source": [
        "from util import load_train_data\n",
        "pos_datapath = \"data/hotelPosT-train.txt\"\n",
        "neg_datapath = \"data/hotelNegT-train.txt\"\n",
        "all_texts, all_labels = load_train_data(pos_datapath, neg_datapath)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-om7MjgTBi4_"
      },
      "source": [
        "### Lets look at what is in the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1vCruk4Bi5A",
        "outputId": "1f6f3d83-d6bc-4990-dc83-098552b25239"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Positive Example ---\n",
            "The Residence Inn Marriott was a fantastic hotel that I have stayed in many times. The staff is extremely friendly and always remember who I am since I travel quite often to this hotel.   The rooms are more than spacious as they boast a full kitchen, full sized couch, flat screen TV, a small dining table and a desk to do work on.   Also, a few nights a week they have free food and drinks on their first floor which is very delightful.  I would recommend this hotel to anyone.\n",
            "\n",
            "--- Negative Example ---\n",
            "I attended a business meeting out of town, and my secretary booked me a room at the Hampton Inn and Suites in Modesto, California. This was the absolute worst hotel stay I have ever experienced! I travel often for business, and in all of my travels I have never been so disappointed with a stay at a hotel or motel. The clerks at the front desk were rude and unwelcoming upon checking into my room. Noisy children filled the hallways at all hours of the night, completely disrupting my sleep. Getting ready in the morning was a total nightmare, as no hot water flowed from my shower. To make matters worse, when I left a complaint in the suggestion box at the front desk, the manager never responded back to rectify the awful situation! Needless to say, I will never stay at this property again or recommend this hotel to anyone.\n"
          ]
        }
      ],
      "source": [
        "def random_sample(texts, labels, label):\n",
        "    data_by_label = {}\n",
        "    for lab, text in zip(labels, texts):\n",
        "        if lab not in data_by_label:\n",
        "            data_by_label[lab] = []\n",
        "        data_by_label[lab].append(text)\n",
        "    return random.choice(data_by_label[label])\n",
        "\n",
        "print(\"--- Positive Example ---\")\n",
        "print(random_sample(all_texts, all_labels, label=1))\n",
        "print(\"\\n--- Negative Example ---\")\n",
        "print(random_sample(all_texts, all_labels, label=0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbDOFZnWBi5B"
      },
      "source": [
        "### Test Data ( WAIT TILL DEADLINE)\n",
        "\n",
        "This is the test dataset that you will need to use to report the results on. This set is the unseen dataset meaning, you are not in anyway supoose to look what is in this dataset. We will release this dataset on the last day of the assignment's deadline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mbhAVHOwBi5B"
      },
      "outputs": [],
      "source": [
        "### RUN THIS ONLY ON DEADLINE ###\n",
        "# Load the test data\n",
        "\n",
        "from util import load_test_data\n",
        "\n",
        "# FIXME\n",
        "test_datapath = \"data/test-dataset.txt\"\n",
        "test_texts, test_labels = load_train_data(test_datapath)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6E0HroyeBi5C"
      },
      "source": [
        "### Task 1.1: Print the number of \"positive\" and \"negative\" samples (5 Points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgTeJY6YBi5C"
      },
      "source": [
        "It is important to know the distribution of the training examples. More often than not, you will have to work with datasets that are not \"balanced\" with respect to the labels of the samples. For this task, print out the number of examples that have label = 1 and label = 0, respectively, in std:out or plot a pie chart."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-6l37vmBi5C",
        "outputId": "bbcf673b-3ef1-4c27-b68c-967bff7ec255"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of positive labels is 95 and the number of negative labels is 94\n"
          ]
        }
      ],
      "source": [
        "### ENTER CODE HERE ###\n",
        "\n",
        "# Note since we have them in two seperate files,\n",
        "# this can also be done with bash commands\n",
        "def label_distribution(labels):\n",
        "    posnum = 0\n",
        "    negnum = 0\n",
        "    for i in labels:\n",
        "      if i == 1:\n",
        "        posnum += 1\n",
        "      elif i == 0:\n",
        "        negnum += 1\n",
        "    print(\"The number of positive labels is \" + str(posnum) + \" and the number\"\n",
        "      + \" of negative labels is \" + str(negnum))\n",
        "label_distribution(all_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yyyN1FlBi5D"
      },
      "source": [
        "### Task 1.2: Split Training and Development Sets (5 Points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6CuVMVoBi5D"
      },
      "source": [
        "For the purpose of coming with the best parameters for the model you will have to split the dataset into training and development sets. Make sure the splits follow the same distribution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fk5mJ98_Bi5D",
        "outputId": "79f6fa06-8b5e-4df1-f17b-04fd19217c5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Label Distribution:\n",
            "The number of positive labels is 76 and the number of negative labels is 75\n",
            "Dev Label Distribution:\n",
            "The number of positive labels is 18 and the number of negative labels is 18\n"
          ]
        }
      ],
      "source": [
        "### ENTER CODE HERE ###\n",
        "\n",
        "import random\n",
        "import math\n",
        "\n",
        "\n",
        "def split_dataset(texts, labels):\n",
        "  pos_texts = texts[0:94]\n",
        "  neg_texts = texts[95:188]\n",
        "  train_texts = []\n",
        "  train_labels = []\n",
        "  dev_texts = []\n",
        "  dev_labels = []\n",
        "\n",
        "  random.shuffle(pos_texts)\n",
        "  random.shuffle(neg_texts)\n",
        "  poslen = math.ceil(0.8 * len(pos_texts))\n",
        "  neglen = math.ceil(0.8 * len(neg_texts))\n",
        "  for i in range(poslen):\n",
        "    train_texts.append(pos_texts[i])\n",
        "    train_labels.append(1)\n",
        "    if i < (len(pos_texts) - poslen):\n",
        "      dev_texts.append(pos_texts[i + poslen])\n",
        "      dev_labels.append(1)\n",
        "  for j in range(neglen):\n",
        "    train_texts.append(neg_texts[j])\n",
        "    train_labels.append(0)\n",
        "    if j < (len(neg_texts) - neglen):\n",
        "      dev_texts.append(neg_texts[j + neglen])\n",
        "      dev_labels.append(0)\n",
        "\n",
        "  return train_texts, train_labels, dev_texts, dev_labels\n",
        "\n",
        "\n",
        "train_texts, train_labels, dev_texts, dev_labels = split_dataset(all_texts, all_labels)\n",
        "\n",
        "print('Train Label Distribution:')\n",
        "label_distribution(train_labels)\n",
        "\n",
        "print('Dev Label Distribution:')\n",
        "label_distribution(dev_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wiu7udU_Bi5D"
      },
      "source": [
        "### Task 1.3: Evaluation Metrics (10 Points)\n",
        "\n",
        "Implement the evaulation metrics: Accuracy, Precision, Recall and F1 score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "BmQgdSJjBi5D"
      },
      "outputs": [],
      "source": [
        "### ENTER CODE HERE ###\n",
        "\n",
        "def accuracy(predicted_labels, true_labels):\n",
        "    correct = 0\n",
        "    i = 0\n",
        "    for i in range(len(predicted_labels)):\n",
        "      if predicted_labels[i] == true_labels[i]:\n",
        "        correct += 1\n",
        "    acc = correct / len(predicted_labels)\n",
        "    return acc\n",
        "\n",
        "def precision(predicted_labels, true_labels):\n",
        "    pallpos = 0\n",
        "    truepos = 0\n",
        "    for i in range(len(predicted_labels)):\n",
        "      if predicted_labels[i] == 1:\n",
        "        pallpos += 1\n",
        "      if predicted_labels[i] == 1 and predicted_labels[i] == true_labels[i]:\n",
        "        truepos += 1\n",
        "    prec = truepos / pallpos\n",
        "    return prec\n",
        "\n",
        "def recall(predicted_labels, true_labels):\n",
        "    rallpos = 0\n",
        "    truepos = 0\n",
        "    for i in range(len(predicted_labels)):\n",
        "      if true_labels[i] == 1:\n",
        "        rallpos += 1\n",
        "      if predicted_labels[i] == 1 and predicted_labels[i] == true_labels[i]:\n",
        "        truepos += 1\n",
        "    rec = truepos / rallpos\n",
        "    return rec\n",
        "\n",
        "\n",
        "def f1_score(predicted_labels, true_labels):\n",
        "    pallpos = 0\n",
        "    truepos = 0\n",
        "    rallpos = 0\n",
        "\n",
        "    for i in range(len(predicted_labels)):\n",
        "      if predicted_labels[i] == 1:\n",
        "        pallpos += 1\n",
        "    for i in range(len(true_labels)):\n",
        "      if true_labels[i] == 1:\n",
        "        rallpos += 1\n",
        "      if predicted_labels[i] == 1 and predicted_labels[i] == true_labels[i]:\n",
        "        truepos += 1\n",
        "    prec = truepos / pallpos\n",
        "    rec = truepos / rallpos\n",
        "    hmean = (2 * prec * rec) / (prec + rec)\n",
        "    return hmean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "UpcN5DSpBi5E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ad195c3-74de-4c59-94fd-bb40ef3a26c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All Test Cases Passed!\n"
          ]
        }
      ],
      "source": [
        "### DO NOT EDIT ###\n",
        "\n",
        "em_test_labels = [0]*6 + [1]*4\n",
        "em_test_predictions = [0]*8 + [1]*2\n",
        "\n",
        "em_test_accuracy = 0.8\n",
        "em_test_precision = 1.0\n",
        "em_test_recall = 0.5\n",
        "em_test_f1 = 2/3\n",
        "\n",
        "assert accuracy(em_test_predictions, em_test_labels) == em_test_accuracy\n",
        "assert precision(em_test_predictions, em_test_labels) == em_test_precision\n",
        "assert recall(em_test_predictions, em_test_labels) == em_test_recall\n",
        "assert f1_score(em_test_predictions, em_test_labels) == em_test_f1\n",
        "\n",
        "print('All Test Cases Passed!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqRtY3nQBi5E"
      },
      "source": [
        "## Section 2: Baselines (Total: 20 Points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yni3OobdBi5E"
      },
      "source": [
        "It is important to come up with baselines for the classifications to compare the more complicated models with. The baselines are also useful as a debugging method for your actual classfication model. You will create two baselines:\n",
        "\n",
        "1. Random Chance\n",
        "2. Naive Bayes Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yx7_O5u-Bi5E"
      },
      "source": [
        "### Task 2.1: Random Chance Classifier (5 Points)\n",
        "\n",
        "A random chance classifier predicts the label according to the label's distribution. As an example, if the label 1 appears 70% of the times in the training set, you predict 70 out of 100 times the label 1 and label 0 30% of the times"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "xddq7AUEBi5E"
      },
      "outputs": [],
      "source": [
        "### ENTER CODE HERE ###\n",
        "\n",
        "def predict_random(train_labels, num_samples):\n",
        "    pos = 0\n",
        "    for i in train_labels:\n",
        "      if i == 1:\n",
        "        pos += 1\n",
        "    distr = pos / len(train_labels)\n",
        "    distrsize = math.ceil(distr * num_samples)\n",
        "\n",
        "    pred = [1]*(distrsize) + [0]*(num_samples - distrsize)\n",
        "\n",
        "    return pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2OCSGDkBi5E"
      },
      "source": [
        "### Task 2.2: Naive Bayes Classifier (Total: 10 Points)\n",
        "\n",
        "In the class, Jim went over how to implement a Naive Bayes Classifier using the tokens in the training samples.\n",
        "In this task, you will do the same. As a preprocessing step, you might want to remove the stop words and lemmatize/stem the words of the texts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6iBUGcpjBi5F"
      },
      "source": [
        "### Spacy Model https://spacy.io\n",
        "\n",
        "To tokenize the text and help extract features from text, we will use the popular spaCy model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "9dMhVI6lBi5F"
      },
      "outputs": [],
      "source": [
        "### DO NOT EDIT ###\n",
        "\n",
        "# Initialize the spacy model\n",
        "nlp = spacy.load('en_core_web_sm')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tl3YJ3yWBi5F"
      },
      "source": [
        "### Task 2.2.1: Play around with spacy (0 Points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXNsyAMyBi5F",
        "outputId": "0d7aae6d-4a8d-490c-ee26-6ed63b4df4e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token Lemma Is_Stopword?\n",
            "This this True\n",
            "is be True\n",
            "an an True\n",
            "amazing amazing False\n",
            "sentence sentence False\n"
          ]
        }
      ],
      "source": [
        "### ENTER CODE HERE ###\n",
        "\n",
        "test_string = \"This is an amazing sentence\"\n",
        "\n",
        "# parse the string with spacy model\n",
        "test_doc = nlp(test_string)\n",
        "\n",
        "print('Token', 'Lemma', 'Is_Stopword?')\n",
        "for token in test_doc:\n",
        "    print(token, token.lemma_, token.is_stop)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uo9785IRBi5G"
      },
      "source": [
        "### Task 2.2.2: Preprocessing (5 Points)\n",
        "\n",
        "Remove stopwords and lemmatize the words of a text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXSsyY2sBi5G",
        "outputId": "975047ad-8a1e-4da2-c5bb-3954c60eb4ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All Test Cases Passed!\n"
          ]
        }
      ],
      "source": [
        "### ENTER CODE HERE ###\n",
        "\n",
        "def pre_process(text: str) -> List[str]:\n",
        "  lemmas = []\n",
        "  nlp_text = nlp(text)\n",
        "  for token in nlp_text:\n",
        "    if not token.is_stop:\n",
        "      lemmas.append(token.lemma_)\n",
        "  return lemmas\n",
        "\n",
        "test_string = \"This sentence needs to be lemmatized\"\n",
        "\n",
        "assert len({'sentence', 'need', 'lemmatize', 'lemmatiz'}.intersection(pre_process(test_string))) >= 3\n",
        "\n",
        "print('All Test Cases Passed!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HArs-4DgBi5H"
      },
      "source": [
        "### Task 2.2.3: The Naive Bayes Class (5 Points)\n",
        "\n",
        "The standard way of implementing classifiers like Naive Bayes is to implement the two methods: \"fit\" and \"predict\". The fit method expects the training data along with labels, and the predict method predicts the labels for the provides texts of samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "e3l-U5F2Bi5H"
      },
      "outputs": [],
      "source": [
        "### ENTER CODE HERE ###\n",
        "\n",
        "class NaiveBayesClassifier:\n",
        "    def __init__(self, num_classes):\n",
        "        self.num_classes = num_classes\n",
        "        self.cls = []\n",
        "        self.prior_cls = {}\n",
        "        self.prob_cls = {}\n",
        "\n",
        "    def fit(self, texts, labels):\n",
        "      # pre-process texts\n",
        "        pr_texts = []\n",
        "        for i in range(len(texts)):\n",
        "          pr_texts.append(pre_process(texts[i]))\n",
        "        #give names to the classes of labels\n",
        "        dcls = {} #number of documents per class/label\n",
        "        for l in labels:\n",
        "          if l not in self.cls:\n",
        "            self.cls.append(l)\n",
        "        #calculate number of documents per class and sort texts\n",
        "        texts_per_class = {}\n",
        "        for cl in self.cls:\n",
        "          doc_in_class_count = 0\n",
        "          for j in range(len(labels)):\n",
        "            if labels[j] == cl:\n",
        "              doc_in_class_count += 1\n",
        "          dcls[cl] = doc_in_class_count\n",
        "          texts_per_class[cl] = []\n",
        "        #sort texts into classes\n",
        "        for t in range(len(texts)):\n",
        "          texts_per_class[labels[t]].append(pr_texts[t])\n",
        "        #calculate vocab, priors and  for all classes\n",
        "        for cl in self.cls:\n",
        "          self.prior_cls[cl] = dcls[cl] / len(texts)\n",
        "        for c in texts_per_class:\n",
        "          class_vocab = {}\n",
        "          vocab_probability = {}\n",
        "          for tpc in texts_per_class[c]:\n",
        "            for w in tpc:\n",
        "              if w not in class_vocab:\n",
        "                class_vocab.update({w : 1})\n",
        "              else:\n",
        "                class_vocab[w] += 1\n",
        "          for v in class_vocab:\n",
        "            vocab_probability[v] = class_vocab[v] / len(class_vocab)\n",
        "          self.prob_cls[c] = vocab_probability\n",
        "\n",
        "    def predict(self, texts):\n",
        "        predicted_classes = []\n",
        "        #pre-process texts\n",
        "        pr_texts = []\n",
        "        for i in range(len(texts)):\n",
        "          pr_texts.append(pre_process(texts[i]))\n",
        "        for j in range(len(pr_texts)):\n",
        "          possibilities = []\n",
        "          for c in self.cls:\n",
        "            c_pr = self.prior_cls[c]\n",
        "            for w in pr_texts[j]:\n",
        "              if w in self.prob_cls[c]:\n",
        "                c_pr = c_pr + self.prob_cls[c][w]\n",
        "              possibilities.append(c_pr)\n",
        "            sorted_possibilities = sorted(possibilities)\n",
        "            for p in range(len(possibilities)):\n",
        "              if possibilities[p] == sorted_possibilities[0]:\n",
        "                predicted_classes.append(c)\n",
        "        return predicted_classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIUal1V_Bi5H"
      },
      "source": [
        "### Task 2.3: Baseline Results  (5 Points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWbKHLw3Bi5I"
      },
      "source": [
        "Since there is not hyperparameter-tuing required for the baselines, we can use the entirety of the training set (no need to split the dataset into train and development). Report the results you achieve with the two baselines by running the following cell:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "H_TT9NMRBi5I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a51367df-176b-4b6f-e213-1f2f86745c8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Chance F1: 0.972972972972973\n",
            "Naive Bayes F1: 0.25\n"
          ]
        }
      ],
      "source": [
        "### DO NOT EDIT ###\n",
        "\n",
        "### DEV SET RESULTS\n",
        "\n",
        "testset_prediction_random = predict_random(train_labels, num_samples=len(dev_labels))\n",
        "print('Random Chance F1:', f1_score(testset_prediction_random, dev_labels))\n",
        "\n",
        "naive_bayes_classifier = NaiveBayesClassifier(num_classes=2)\n",
        "naive_bayes_classifier.fit(train_texts, train_labels)\n",
        "testset_predictions_nb = naive_bayes_classifier.predict(dev_texts)\n",
        "print('Naive Bayes F1:', f1_score(testset_predictions_nb, dev_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iFIn7Wz-Bi5I"
      },
      "outputs": [],
      "source": [
        "### DO NOT EDIT ###\n",
        "### RUN THIS ONLY ON DEADLINE ###\n",
        "### TEST SET RESULTS\n",
        "\n",
        "testset_prediction_random = predict_random(all_labels, num_samples=len(test_labels))\n",
        "print('Random Chance F1:', f1_score(testset_prediction_random, test_labels))\n",
        "\n",
        "naive_bayes_classifier = NaiveBayesClassifier(num_classes=2)\n",
        "naive_bayes_classifier.fit(all_texts, all_labels)\n",
        "testset_predictions_nb = naive_bayes_classifier.predict(test_texts)\n",
        "print('Naive Bayes F1:', f1_score(testset_predictions_nb, test_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbb3sf8JBi5I"
      },
      "source": [
        "## Section 3: Logistic Regression on Features (Total: 60 Points)\n",
        "\n",
        "Now let's try building a logistic regression based classifier on hand-engineered features.\n",
        "\n",
        "The following tasks are going to be the implementation of the components required in building a Logistic Regressor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXxCwtDLBi5I"
      },
      "source": [
        "### Task 3.0: Feature Extraction (20 points)\n",
        "\n",
        "This is perhaps the most challenging part of this assignment. In the class, we went over how to featurize text for a classification system for sentiment analysis. In this assignment, you should implement and build upon this to accuractely classify the hotel reviews.\n",
        "\n",
        "This task requires a thorough understanding of the dataset to answer the important question, \"What is in the data?\". Please go through some of the datapoints and convert the signals that you think might help in identifying \"sentiment\" as features.\n",
        "\n",
        "Please refer to the section in Jim's book that illustrates the process of feature engineering for this task. We have attached an image of the table below:\n",
        "\n",
        "![image.png](attachment:image.png)\n",
        "\n",
        "Please use the files with postive and negative words attached in the assignment: [positive_words.txt](data/poisitive-words.txt) and  [negative_words.txt](data/negative-words.txt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "2RHaYOLQBi5J"
      },
      "outputs": [],
      "source": [
        "def feature_textlength(text: spacy.tokens.doc.Doc):\n",
        "    return len(text)\n",
        "\n",
        "def feature_poscount(text: spacy.tokens.doc.Doc):\n",
        "    poscount = 0\n",
        "    words = []\n",
        "    with open(\"data/positive-words.txt\") as f:\n",
        "      for w in f:\n",
        "        word = w.strip()\n",
        "        words.append(word)\n",
        "      for t in text:\n",
        "        if t.lemma_ in words:\n",
        "          poscount += 1\n",
        "    return poscount\n",
        "\n",
        "def feature_negcount(text: spacy.tokens.doc.Doc):\n",
        "    negcount = 0\n",
        "    words = []\n",
        "    with open(\"data/negative-words.txt\") as f:\n",
        "      for w in f:\n",
        "        word = w.strip()\n",
        "        words.append(word)\n",
        "      for t in text:\n",
        "        if t.lemma_ in words:\n",
        "          negcount += 1\n",
        "    return negcount\n",
        "\n",
        "def feature_wordlength(text: spacy.tokens.doc.Doc):\n",
        "    av_wordlength = 0\n",
        "    wordlengths = 0\n",
        "    wordcount = 0\n",
        "    for w in text:\n",
        "      wordcount += 1\n",
        "      wordlengths = wordlengths + len(w)\n",
        "    av_wordlength = wordlengths / wordcount\n",
        "    return av_wordlength\n",
        "\n",
        "def feature_pivots(text: spacy.tokens.doc.Doc):\n",
        "    checklist = [\"well\", \"turns out\", \"turned out\", \"apparently\", \"seems\",\n",
        "                 \"seemed\", \"discovered\", \"surprised\", \"at first\"]\n",
        "    pivotcount = 0\n",
        "    comparison = []\n",
        "    for t in text:\n",
        "      comparison.append(t.lemma_)\n",
        "    for w in comparison:\n",
        "      if w in checklist:\n",
        "        pivotcount += 1\n",
        "    return pivotcount\n",
        "\n",
        "def feature_pronouns(text: spacy.tokens.doc.Doc):\n",
        "    checklist = [\"I\", \"we\", \"We\", \"you\", \"You\"]\n",
        "    pronouncount = 0\n",
        "    comparison = []\n",
        "    for t in text:\n",
        "      comparison.append(t.lemma_)\n",
        "    for w in comparison:\n",
        "      if w in checklist:\n",
        "        pronouncount += 1\n",
        "    return pronouncount\n",
        "\n",
        "def feature_logwordcount(text: spacy.tokens.doc.Doc):\n",
        "    return math.log(len(text))\n",
        "\n",
        "\n",
        "def extract_features(text: spacy.tokens.doc.Doc):\n",
        "    features = []\n",
        "    features.append(feature_poscount(text))\n",
        "    features.append(feature_negcount(text))\n",
        "    features.append(feature_wordlength(text))\n",
        "    features.append(feature_pivots(text))\n",
        "    features.append(feature_pronouns(text))\n",
        "    features.append(feature_logwordcount(text))\n",
        "    features.append(feature_textlength(text))\n",
        "    return features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "SW7X_QyZBi5J"
      },
      "outputs": [],
      "source": [
        " ### ENTER CODE HERE ###\n",
        "### DO NOT CHANGE THE SIGNATURE OF THE function THOUGH ###\n",
        "\n",
        "def featurize_data(texts, labels):\n",
        "    features = [\n",
        "        extract_features(doc) for doc in nlp.pipe(texts)\n",
        "    ]\n",
        "    return torch.FloatTensor(features), torch.FloatTensor(labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5M_XE4yBi5J"
      },
      "source": [
        "### Task 3.0.2: Feature Scaling (10 Points)\n",
        "\n",
        "In this task we will use the data normalization technique to ensure the scales of the feature are consistent.\n",
        "After featurizing the dataset, we need to call the following function before passing it to the classifier\n",
        "\n",
        "#### Normalization Formula\n",
        "\n",
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "xNNS3t19Bi5J"
      },
      "outputs": [],
      "source": [
        "### ENTER CODE HERE ###\n",
        "\n",
        "def normalize(features: torch.Tensor) -> torch.Tensor:\n",
        "    i = 0\n",
        "    while i < features.size(dim=1):\n",
        "      j = features[:,i]\n",
        "      smallest = torch.min(j)\n",
        "      largest = torch.max(j)\n",
        "      j = (j - smallest) / (largest - smallest)\n",
        "      i += 1\n",
        "    return features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aW5f-MLHBi5J"
      },
      "source": [
        "## Training a Logistic Regression Classifier (Total: 30 Points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDgoCwIJBi5K"
      },
      "source": [
        "In this section, you will implement the components needed to train the binary classifier using logistic regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-r74alx5Bi5K"
      },
      "source": [
        "### Here we define our pytorch logistic regression classifier (DO NOT EDIT THIS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "s8QF7iHnBi5K"
      },
      "outputs": [],
      "source": [
        "class SentimentClassifier(torch.nn.Module):\n",
        "    def __init__(self, input_dim: int):\n",
        "        super().__init__()\n",
        "        # We force output to be one, since we are doing binary logistic regression\n",
        "        self.output_size = 1\n",
        "        self.coefficients = torch.nn.Linear(input_dim, self.output_size)\n",
        "        # Initialize weights. Note that this is not strictly necessary,\n",
        "        # but you should test different initializations per lecture\n",
        "        initialize_weights(self.coefficients)\n",
        "\n",
        "    def forward(self, features: torch.Tensor):\n",
        "        # We predict a number by multipling by the coefficients\n",
        "        # and then take the sigmoid to turn the score as logits\n",
        "        return torch.sigmoid(self.coefficients(features))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdDySERFBi5K"
      },
      "source": [
        "### Task 3.1: Initialize the weights. (5 Points)\n",
        "\n",
        "Initialization of the parameters is an important step to ensure the SGD algorithm converges to a global optimum. Typically, we need to try different initialization methods and compare the accuracy we achieve for the development set. In this task, implement the function that initializes the parameters to ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "0SsqsLI9Bi5K"
      },
      "outputs": [],
      "source": [
        "### ENTER CODE HERE ###\n",
        "\n",
        "def initialize_weights(coefficients):\n",
        "    torch.nn.init.normal_(coefficients.weight.data )\n",
        "    return coefficients"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HkjCk23Bi5L"
      },
      "source": [
        "Let's build a training function similar to the linear regressor from the tutorial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngJbzSenBi5L"
      },
      "source": [
        "### Task 3.2: Logistic Loss Function (10 Points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "ZyIDT-XfBi5L"
      },
      "outputs": [],
      "source": [
        "### ENTER CODE HERE ###\n",
        "\n",
        "def logistic_loss(prediction: torch.Tensor, label: torch.Tensor) -> torch.Tensor:\n",
        "    loss = torch.mean(torch.neg(torch.add(torch.mul(label, torch.log(prediction)), torch.mul((1 - label), torch.log(1 - prediction)))))\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddnbzd53Bi5M"
      },
      "source": [
        "### Task 3.3: Create an SGD optimizer (0 Points)\n",
        "\n",
        "We have already provided the implementation of how to create the SGD optimizer\n",
        "\n",
        "You may try different optimizers refering to the docs provided"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "gsZEZ0dhBi5M"
      },
      "outputs": [],
      "source": [
        "### ENTER CODE HERE ###\n",
        "\n",
        "def make_optimizer(model, learning_rate) -> torch.optim:\n",
        "    return torch.optim.SGD(model.parameters(), learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAkJe2heBi5M"
      },
      "source": [
        "### Task 3.5: Converting Logits into Predictions (5 Points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "3WRp9VGMBi5M"
      },
      "outputs": [],
      "source": [
        "### ENTER CODE HERE ###\n",
        "\n",
        "def predict(model, features):\n",
        "    with torch.no_grad():\n",
        "      probabilities = model(features)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xr9ER65QBi5M"
      },
      "source": [
        "### Training Function (DO NOT EDIT THIS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "wrVOaV4ABi5N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fb1becf-8942-4008-8389-61d50c1e1516"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-29-04ae77a65f35>:3: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm\n"
          ]
        }
      ],
      "source": [
        "### DO NOT EDIT ###\n",
        "\n",
        "from tqdm.autonotebook import tqdm\n",
        "import random\n",
        "\n",
        "\n",
        "def training_loop(\n",
        "    num_epochs,\n",
        "    batch_size,\n",
        "    train_features,\n",
        "    train_labels,\n",
        "    dev_features,\n",
        "    dev_labels,\n",
        "    optimizer,\n",
        "    model\n",
        "):\n",
        "    samples = list(zip(train_features, train_labels))\n",
        "    random.shuffle(samples)\n",
        "    batches = []\n",
        "    for i in range(0, len(samples), batch_size):\n",
        "        batches.append(samples[i:i+batch_size])\n",
        "    print(\"Training...\")\n",
        "    for i in range(num_epochs):\n",
        "        losses = []\n",
        "        for batch in tqdm(batches):\n",
        "            # Empty the dynamic computation graph\n",
        "            features, labels = zip(*batch)\n",
        "            features = torch.stack(features)\n",
        "            labels = torch.stack(labels)\n",
        "            optimizer.zero_grad()\n",
        "            # Run the model\n",
        "            logits = model(features)\n",
        "            # Compute loss\n",
        "            loss = logistic_loss(torch.squeeze(logits), labels)\n",
        "            # In this logistic regression example,\n",
        "            # this entails computing a single gradient\n",
        "            loss.backward()\n",
        "            # Backpropogate the loss through our model\n",
        "\n",
        "            # Update our coefficients in the direction of the gradient.\n",
        "            optimizer.step()\n",
        "             # For logging\n",
        "            losses.append(loss.item())\n",
        "\n",
        "        # Estimate the f1 score for the development set\n",
        "        dev_f1 = f1_score(predict(model, dev_features), dev_labels)\n",
        "        print(f\"epoch {i}, loss: {sum(losses)/len(losses)}\")\n",
        "        print(f\"Dev F1 {dev_f1}\")\n",
        "\n",
        "    # Return the trained model\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZK2RVG06Bi5N"
      },
      "source": [
        "### Task 3.6: Train the classifier (10 Points)\n",
        "\n",
        "Run the following cell to train a logistic regressor on your hand-engineered features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "A2rlrIKCBi5N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423,
          "referenced_widgets": [
            "190d045c711f40e39c0b8fb2518e59cc",
            "d9b077508e3d466092058c230e4405f9",
            "22c78f4fe86340189d2ac3710c1ec82b",
            "8c449735e886473ca7467a7a27d9870e",
            "8db90621c7f74285add0f3600839f58d",
            "41b701bc04aa462696c811f468c04e75",
            "22265b0140cb4d29b791d7663dbcb8f1",
            "2cff969ca476403381c5e2aa648f6233",
            "5a3a1ae907e64fb78ed7cb0d33406aa1",
            "b041a5c163d7418198437a6e26e2f59c",
            "5fe9a577f9bc433a88429a6de9f96eea"
          ]
        },
        "outputId": "0b04d015-3e5b-40dc-86b0-1da56711fa7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "190d045c711f40e39c0b8fb2518e59cc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-5f5819c2413f>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_optimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m trained_model = training_loop(\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-04ae77a65f35>\u001b[0m in \u001b[0;36mtraining_loop\u001b[0;34m(num_epochs, batch_size, train_features, train_labels, dev_features, dev_labels, optimizer, model)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;31m# Estimate the f1 score for the development set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mdev_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"epoch {i}, loss: {sum(losses)/len(losses)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Dev F1 {dev_f1}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-33-e416956386f0>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(model, features)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0mprobabilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m       \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprobabilities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'predict'"
          ]
        }
      ],
      "source": [
        "### DO NOT EDIT ###\n",
        "\n",
        "num_epochs = 100\n",
        "\n",
        "train_features, train_labels_tensor = featurize_data(train_texts, train_labels)\n",
        "train_features = normalize(train_features)\n",
        "dev_features, dev_labels_tensor = featurize_data(dev_texts, dev_labels)\n",
        "dev_features = normalize(dev_features)\n",
        "model = SentimentClassifier(train_features.shape[1])\n",
        "optimizer = make_optimizer(model, learning_rate=0.01)\n",
        "\n",
        "trained_model = training_loop(\n",
        "    num_epochs,\n",
        "    16,\n",
        "    train_features,\n",
        "    train_labels_tensor,\n",
        "    dev_features,\n",
        "    dev_labels_tensor,\n",
        "    optimizer,\n",
        "    model\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLBJXauuBi5N"
      },
      "source": [
        "### Task 3.7: Get the predictions on the Test Set using the Trained model and print the F1 score (10 Points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0PyO5h30Bi5N"
      },
      "outputs": [],
      "source": [
        "### DO NOT EDIT ###\n",
        "\n",
        "### DEV SET RESULTS\n",
        "\n",
        "test_features, test_labels = featurize_data(dev_texts, dev_labels)\n",
        "print('Logistic Regression Results:')\n",
        "print('Accuracy:', accuracy(predict(trained_model, test_features), test_labels))\n",
        "print('F1-score', f1_score(predict(trained_model, test_features), test_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vr4JELxzBi5O"
      },
      "outputs": [],
      "source": [
        "### DO NOT EDIT ###\n",
        "### RUN THIS ONLY ON DEADLINE ###\n",
        "### TEST SET RESULTS\n",
        "\n",
        "test_features, test_labels = featurize_data(test_texts, test_labels)\n",
        "print('Logistic Regression Results:')\n",
        "print('Accuracy:', accuracy(predict(trained_model, test_features), test_labels))\n",
        "print('F1-score', f1_score(predict(trained_model, test_features), test_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shHzqHozBi5O"
      },
      "source": [
        "## Written Assignment (60 Points)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UzxGcMjNUGqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpkj8j4TBi5O"
      },
      "source": [
        "Written assignment tests the understanding of the student for the assignment's task. We have split the writing into sections. You will need to write 1-2 paragraphs describing the sections. Please be concise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVbLFoy2Bi5O"
      },
      "source": [
        "### In your own words, describe what the task is (20 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNAzDcDHBi5O"
      },
      "source": [
        "The task is to build a model which will discrimate between reviews that are basically positive and reviews that are basically negative. This requires a training process to learn the distinguishing features that allow this task to be done. The logistic regression model adjusts weights during training until the model has reached a best fit for that training data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLeZIklpBi5P"
      },
      "source": [
        "### Describe your method for the task (10 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oor6Wll8Bi5P"
      },
      "source": [
        "Important details about the implementation. Feature engineering, parameter choice etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWCodK1iBi5P"
      },
      "source": [
        "### Experiment Results (10 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YU7kUc8RBi5P"
      },
      "source": [
        "Typically a table summarizing all the different experiment results for various parameter choices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNRS2pxFBi5Q"
      },
      "source": [
        "### Discussion (20 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEca7_DtBi5Q"
      },
      "source": [
        "Key takeaway from the assignment. Why is the method good? shortcomings? how would you improve? Additional thoughts?"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    },
    "colab": {
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "190d045c711f40e39c0b8fb2518e59cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d9b077508e3d466092058c230e4405f9",
              "IPY_MODEL_22c78f4fe86340189d2ac3710c1ec82b",
              "IPY_MODEL_8c449735e886473ca7467a7a27d9870e"
            ],
            "layout": "IPY_MODEL_8db90621c7f74285add0f3600839f58d"
          }
        },
        "d9b077508e3d466092058c230e4405f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41b701bc04aa462696c811f468c04e75",
            "placeholder": "​",
            "style": "IPY_MODEL_22265b0140cb4d29b791d7663dbcb8f1",
            "value": "100%"
          }
        },
        "22c78f4fe86340189d2ac3710c1ec82b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2cff969ca476403381c5e2aa648f6233",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5a3a1ae907e64fb78ed7cb0d33406aa1",
            "value": 10
          }
        },
        "8c449735e886473ca7467a7a27d9870e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b041a5c163d7418198437a6e26e2f59c",
            "placeholder": "​",
            "style": "IPY_MODEL_5fe9a577f9bc433a88429a6de9f96eea",
            "value": " 10/10 [00:00&lt;00:00, 235.16it/s]"
          }
        },
        "8db90621c7f74285add0f3600839f58d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41b701bc04aa462696c811f468c04e75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22265b0140cb4d29b791d7663dbcb8f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2cff969ca476403381c5e2aa648f6233": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a3a1ae907e64fb78ed7cb0d33406aa1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b041a5c163d7418198437a6e26e2f59c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5fe9a577f9bc433a88429a6de9f96eea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}